{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Nature Conservancy Fisheries Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fish_data as fd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module fish_data:\n",
      "\n",
      "NAME\n",
      "    fish_data\n",
      "\n",
      "DESCRIPTION\n",
      "    fish_data module contains the helper functions for the model build of the\n",
      "    Nature Conservancy Fisheries Kaggle Competition.\n",
      "    \n",
      "    Dependencies:\n",
      "        * numpy as np\n",
      "        * os\n",
      "        * scipy.ndimage as ndimage\n",
      "        * scipy.misc as misc\n",
      "        * scipy.special as special\n",
      "        * matplotlib.pyplot as plt\n",
      "\n",
      "FUNCTIONS\n",
      "    count_nodes(std_y, std_x, pool_steps, final_depth)\n",
      "        Calculates the number of flattened nodes after a number of 'VALID' pool\n",
      "        steps of strides = [1,2,2,1]\n",
      "    \n",
      "    generate_balanced_epoch(min_each, shuffle=True)\n",
      "        Function to generate a list of filenames to be used for each training epoch\n",
      "        with a corresponding label array.  Most file names will be used  multiple  times\n",
      "        in order that each fish is drawn into a training batch an equivalent number of\n",
      "        times.\n",
      "    \n",
      "    generate_filenames_list()\n",
      "        Iterates through the 'data/train' folders of the working directory to\n",
      "        generate a list of filenames\n",
      "    \n",
      "    make_batch(filename_list, offset, batch_size, std_y, std_x, normalize=True, mutate=True)\n",
      "        Iterates through a filename list to load an RGB image of any pixel\n",
      "        dimensions, mutate the image using the `mutate_image` function, normalize\n",
      "        the pixel values and pixel dimensions using the `standardize` function, and\n",
      "        return an array for concatenation into a 4D array.  The function can be used\n",
      "        to assemble training batches or to bring the validation array into the\n",
      "        kernel environment.\n",
      "    \n",
      "    make_label(filename_list, offset, batch_size)\n",
      "        Returns the label associated with a training batch generation.  Fn also\n",
      "        navigates the ends of the epoch list.\n",
      "    \n",
      "    mutate_image(image)\n",
      "        Receives an image array and returns an image array with a random set of\n",
      "            distortions.\n",
      "        Distortions include:\n",
      "            * flip horizontally (p = 0.5)\n",
      "            * flip vertically (p = 0.5)\n",
      "            * slight distortion of coloring (random sigma for each channel - see\n",
      "                shift_colour fn in this module)\n",
      "            * random horizontal shift (image is cropped vertically between 1/15 to\n",
      "                1/20 the image. top or bottom is randomly chosen for chop.)\n",
      "            * random vertical shift (image is cropped horizontally between 1/15 to\n",
      "                1/20 of the image.  left or right is randomly chosen for chop.)\n",
      "    \n",
      "    shift_colour(image, channel, sigma)\n",
      "        Shifts the colour of an RGB image by sigma\n",
      "    \n",
      "    show_panel(image)\n",
      "    \n",
      "    standardize(image, std_y, std_x, normalize=True)\n",
      "        Normalizes and resizes an image array to a standard height, length, and\n",
      "        pixel range.\n",
      "\n",
      "FILE\n",
      "    /Users/ccthomps/Documents/Python Files/Kaggle Competitions/Nature Conservancy Fisheries/fish_data.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a list of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 filenames in the master set list\n"
     ]
    }
   ],
   "source": [
    "fish_filenames = fd.generate_filenames_list()\n",
    "print(\"There are {} filenames in the master set list\".format(len(fish_filenames)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish_label_arr = fd.make_label(fish_filenames, 0, len(fish_filenames))\n",
    "fish_label_arr.shape\n",
    "fish_label_arr[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3477, 8), (300, 8)]\n"
     ]
    }
   ],
   "source": [
    "valid_size = 300\n",
    "files_train, files_val, y_train, y_val = train_test_split(fish_filenames, fish_label_arr, test_size = valid_size)\n",
    "print([x.shape for x in [y_train, y_val]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging Graph and session calls with input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and Session Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "std_y = 300\n",
    "std_x = 500\n",
    "\n",
    "# General\n",
    "num_channels = 3\n",
    "num_labels = 8\n",
    "batch_size = 30\n",
    "stddev = 0.2\n",
    "\n",
    "# convolution\n",
    "kernel_sizes = [12, 3, 3, 3, 3, 3]\n",
    "conv_depths = [64, 128, 256, 512, 256, 128]\n",
    "final_depth = conv_depths[-1]\n",
    "\n",
    "\n",
    "#dropout\n",
    "kp = 0.75\n",
    "\n",
    "# fully connected\n",
    "fc1_depth = 256\n",
    "fc2_depth = 64\n",
    "\n",
    "#regularization\n",
    "beta = 1e-1 \n",
    "\n",
    "# Learning rate\n",
    "init_rate = 5e-3\n",
    "per_steps = 6000\n",
    "decay_rate = 0.75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# epochs\n",
    "num_epochs = 5\n",
    "# path for tensorboard summary file to be written\n",
    "logs_path = os.getcwd()+'/TB_logs'\n",
    "valid_every = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'GRAPH.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [0 0 0 0 1 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [0 0 0 0 0 0 0 1]\n",
      "(100, 167, 3) [0 0 0 0 1 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n",
      "(100, 167, 3) [1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "%run -i 'SESSION.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.variables.Variable at 0x1145720b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
