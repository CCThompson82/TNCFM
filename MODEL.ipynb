{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Nature Conservancy Fisheries Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fish_data as fd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module fish_data:\n",
      "\n",
      "NAME\n",
      "    fish_data\n",
      "\n",
      "DESCRIPTION\n",
      "    fish_data module contains the helper functions for the model build of the\n",
      "    Nature Conservancy Fisheries Kaggle Competition.\n",
      "    \n",
      "    Dependencies:\n",
      "        * numpy as np\n",
      "        * os\n",
      "        * scipy.ndimage as ndimage\n",
      "        * scipy.misc as misc\n",
      "        * scipy.special as special\n",
      "        * matplotlib.pyplot as plt\n",
      "        * tensorflow as tf\n",
      "\n",
      "FUNCTIONS\n",
      "    count_nodes(x, y, kernel, stride, conv_depth, pad='SAME')\n",
      "        Calculates the number of total nodes present in the next layer of a\n",
      "        convolution OR max_pooling event.\n",
      "    \n",
      "    decode_image(image_name, size, num_channels=3, mean_channel_vals=[155.0, 155.0, 155.0], mutate=False, crop='random', crop_size=224)\n",
      "        Converts a dequeued image read from filename to a single tensor array,\n",
      "        with modifications:\n",
      "            * smallest dimension resized to standard height and width supplied in size param\n",
      "            * each channel centered to mean near zero.  Deviation is not normalized.\n",
      "            * if mutate == True :\n",
      "                * random flip left right\n",
      "                * random flip up down\n",
      "                * TODO : random colour adjustment\n",
      "                * random crop from standard size to crop size (e.g. 256x256 to 224x224)\n",
      "    \n",
      "    generate_balanced_filenames_epoch(f_list, labels, shuffle=True)\n",
      "        Returns a shuffled list of filenames, of which some will be duplicates, such\n",
      "        that each fish class is represented equally, along with corresponding one-hot\n",
      "        labels for the list.\n",
      "    \n",
      "    generate_filenames_list(subdirectory='data/train/', subfolders=True)\n",
      "        Iterates through the default 'data/train' folders of the working directory to\n",
      "        generate a list of filenames\n",
      "    \n",
      "    make_labels(filename_list, directory_string='train/', end_string='/img')\n",
      "        Receives a list of filenames and returns an ordered one-hot label\n",
      "        array by finding the fish species ID within the filename string.\n",
      "    \n",
      "    process_batch(f_list, labels, offset, batch_size, std_size, crop_size, crop_mode='centre', pixel_offsets=[155.0, 155.0, 155.0], mutation=False)\n",
      "        Fn preprocesses a batch of images and collects associated labels for input\n",
      "        into a tensorflow graph placeholder.\n",
      "    \n",
      "    show_panel(image)\n",
      "        Convenience function for showing an inline montage of the colour and merged channels\n",
      "\n",
      "FILE\n",
      "    /Users/ccthomps/Documents/Python Files/Kaggle Competitions/Nature Conservancy Fisheries/fish_data.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a list of filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3777 filenames in the master set list\n",
      "There are 1000 filenames in the test set list\n"
     ]
    }
   ],
   "source": [
    "fish_filenames = fd.generate_filenames_list('data/train/', subfolders = True)\n",
    "print(\"There are {} filenames in the master set list\".format(len(fish_filenames)))\n",
    "test_filenames = fd.generate_filenames_list('data/test_stg1/', subfolders = False)\n",
    "print(\"There are {} filenames in the test set list\".format(len(test_filenames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Dictionary of image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid set filename dimensions downloaded correctly: True\n",
      "Training/Valid set filename dimensions downloaded correctly: True\n"
     ]
    }
   ],
   "source": [
    "with open('dimensions_dict.json') as f:\n",
    "    dim_dict = json.load(f)\n",
    "    \n",
    "print(\"Training/Valid set filename dimensions downloaded correctly: {}\".format(\n",
    "        dim_dict.get(fish_filenames[0]) == [720, 1280, 3]))\n",
    "print(\"Training/Valid set filename dimensions downloaded correctly: {}\".format(\n",
    "        dim_dict.get(test_filenames[0]) == [720, 1280, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the labels for the master set list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot labels generated correctly: True\n"
     ]
    }
   ],
   "source": [
    "fish_label_arr = fd.make_labels(fish_filenames, 'train/', '/img')\n",
    "fish_label_arr.shape\n",
    "print(\"One-hot labels generated correctly: {}\".format(all(np.sum(fish_label_arr, 0) == [1719, 200, 117, 67, 465, 299, 176, 734]) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish counts: [1719  200  117   67  465  299  176  734]\n",
      "New fish counts: [1719 1719 1719 1719 1719 1719 1719 1719]\n"
     ]
    }
   ],
   "source": [
    "f_list, f_labels = fd.generate_balanced_filenames_epoch(fish_filenames, fish_label_arr, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle and split the master set list into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 500\n",
      "Training set size: 13252\n"
     ]
    }
   ],
   "source": [
    "valid_size = 500\n",
    "files_train, files_val, y_train, y_val = train_test_split(f_list, f_labels, test_size = valid_size)\n",
    "print(\"Validation set size: {}\".format(y_val.shape[0]))\n",
    "print(\"Training set size: {}\".format(y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_data, val_labels = fd.process_batch(files_val, y_val, offset = 0, batch_size = 500, \n",
    "                        std_size = 256, crop_size = 224, crop_mode = 'centre', \n",
    "                        pixel_offsets = [96.482, 107.203,99.974], mutation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-735ba7b48057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cropped validation set is {} kb\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val' is not defined"
     ]
    }
   ],
   "source": [
    "print(val.shape)\n",
    "print(\"Cropped validation set is {} kb\".format(val.nbytes/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph and Session Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'PARAMETERS.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version_ID = 'v2.0.0.4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'GRAPH.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run -i 'SESSION.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Notes during run \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(W.shape[3]) :\n",
    "    print(i)\n",
    "    plt.imshow(W[:,:,:,i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros([11,11,3,96]).reshape().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
